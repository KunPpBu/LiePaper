---
title: "MU3D Lie Detection Report"
author: "Kun Bu"
date: "2022-07-29"
output: pdf_document
---

```{r}
library(reshape2)
library(factoextra)
library(psych)
library(corrplot)
library(FactoMineR)
library(devtools)
install_github('sinhrks/ggfortify')
library(ggfortify)
library(e1071)
library(caret)
library(randomForest)
#import video level dataset
MU3D_Video_Level_Data0 <- read.csv("MU3D_Video_Level_Data.csv")
head(MU3D_Video_Level_Data0)
```

## Boxplot for variables 
```{r}
#remove veractiy first
MU3D_Video_Level_Data <- MU3D_Video_Level_Data0[,-3]
str(MU3D_Video_Level_Data)
#scaled
colnames(MU3D_Video_Level_Data)

MU3D_Video_Level_Data.scaled <- data.frame(scale(MU3D_Video_Level_Data[,-c(1,13)]))

#level veractiy
levels0 <- unique(c(MU3D_Video_Level_Data0$Veracity, MU3D_Video_Level_Data0$Veracity))
#add veracity back
MU3D_Video_Level_Data.scaled$Veracity <- factor(MU3D_Video_Level_Data0$Veracity,levels = levels0)
#melt data for boxplot
MU3D_Video_Level_Data.scaled.melt <- melt(MU3D_Video_Level_Data.scaled, id.var = "Veracity")

#plot boxplot
ggplot(data = MU3D_Video_Level_Data.scaled.melt, aes(x=Veracity, y = value))+
  geom_boxplot() + 
  facet_wrap(~variable, ncol=2)

```


## SVM split train and test 80/20

```{r}
smp_size_raw <- floor(0.80 * nrow(MU3D_Video_Level_Data.scaled))
train_ind_raw <- sample(nrow(MU3D_Video_Level_Data.scaled), size = smp_size_raw)
train_raw.df <- as.data.frame(MU3D_Video_Level_Data.scaled[train_ind_raw, ])
test_raw.df <- as.data.frame(MU3D_Video_Level_Data.scaled[-train_ind_raw, ])
levels <- unique(c(train_raw.df$Veracity, test_raw.df$Veracity))
test_raw.df$Veracity  <- factor(test_raw.df$Veracity, levels=levels)
train_raw.df$Veracity <- factor(train_raw.df$Veracity, levels=levels)

# tuning best svm model for linear kernel
linear.tune <- tune.svm(Veracity ~ ., data = train_raw.df,
                        kernel = "linear",
                        cost = c(0.001, 0.01, 0.1, 1, 5, 10))
summary(linear.tune) #best cost is 1, misclassification rate no larger than 25%
best.linear <- linear.tune$best.model
linear.test <- predict(best.linear, newdata = test_raw.df)
table(linear.test, test_raw.df$Veracity)
confusionMatrix(linear.test, test_raw.df$Veracity, dnn = c("Prediction", "Reference")) # 76.6% accuracy, kappa = 0.54

# 
# # tuning best svm model for sigmoid kernel
# sigmoid.tune <- tune.svm(Veracity ~. ,data = train_raw.df,
#                          kernel = "sigmoid",
#                          gamma = c(0.1,0.5,1,2,3,4),
#                          coef0 = c(0.1,0.5,1,2,3,4))
# summary(sigmoid.tune)
# best.sigmoid <- sigmoid.tune$best.model
# sigmoid.test <- predict(best.sigmoid, test_raw.df)
# table(sigmoid.test,test_raw.df$Veracity)
# confusionMatrix(sigmoid.test, test_raw.df$Veracity, dnn = c("Prediction", "Reference")) # poor 64%, kappa= 0.27 drop this kernel



# tuning best svm model for polynomial kernel
poly.tune <- tune.svm(Veracity ~ ., data = train_raw.df,
                        kernel = "polynomial",
                        degree = c(2, 3, 4, 5, 6),
                        coef0 = c(0.1, 0.5, 1, 2, 3, 4))
summary(poly.tune) #best degree is 3,coef0 = 3,  misclassification rate no larger than 17%( better than linear kernel)
best.poly <- poly.tune$best.model
poly.test <- predict(best.poly, newdata = test_raw.df)
table(poly.test, test_raw.df$Veracity)
confusionMatrix(poly.test, test_raw.df$Veracity, dnn = c("Prediction", "Reference")) # 78.12% accuracy, kappa = 0.56




# tuning best svm model for radial kernel
rad.tune <- tune.svm(Veracity ~ ., data = train_raw.df,
                      kernel = "radial",
                      gamma = c(0.1, 0.5, 1, 2, 3, 4))
summary(rad.tune) #best gamma = 0.1,  misclassification rate no larger than 19%( better than linear kernel, but not good as polynomial)
best.rad <- rad.tune$best.model
rad.test <- predict(best.rad, newdata = test_raw.df)
table(rad.test, test_raw.df$Veracity)
confusionMatrix(rad.test, test_raw.df$Veracity, dnn = c("Prediction", "Reference")) # 79% accuracy, kappa = 0.6 


# feature extraction
set.seed(3117)
rfeCNTL <- rfeControl(functions = lrFuncs, method = "cv", number = 11)
svm.features <- rfe(train_raw.df[,1:11], train_raw.df[,12],
                    sizes = c(11, 10, 9, 8, 7, 6, 5),
                    rfeControl = rfeCNTL,
                    method = "svmLinear")
svm.features
svm.features$fit$coefficients # Accuracy, TruthProp, VidLength_ms, VidLength_sec, Valence 



# use above 8 features to train polynomial svm

#SVM split train and test 80/20

train_raw.df <- as.data.frame(MU3D_Video_Level_Data.scaled[train_ind_raw, c(1,4,5,7,8,12)])
test_raw.df <- as.data.frame(MU3D_Video_Level_Data.scaled[-train_ind_raw, c(1,4,5,7,8,12)])
levels <- unique(c(train_raw.df$Veracity, test_raw.df$Veracity))
test_raw.df$Veracity  <- factor(test_raw.df$Veracity, levels=levels)
train_raw.df$Veracity <- factor(train_raw.df$Veracity, levels=levels)
#write.csv(test_raw.df, "test_raw.df.csv")
#write.csv(train_raw.df,"train_raw.df.csv")

# tuning best svm model for polynomial kernel
poly.tune <- tune.svm(Veracity ~ ., data = train_raw.df,
                      kernel = "polynomial",
                      degree = c(2, 3, 4, 5, 6),
                      coef0 = c(0.1, 0.5, 1, 2, 3, 4))
summary(poly.tune) #best degree is 4,coef0 = 4,  misclassification rate no larger than 19%( better than linear kernel)
best.poly <- poly.tune$best.model
poly.test <- predict(best.poly, newdata = test_raw.df)
table(poly.test, test_raw.df$Veracity)
confusionMatrix(poly.test, test_raw.df$Veracity, dnn = c("Prediction", "Reference")) # 95.31% accuracy, kappa = 0.90

```

## Random Forest 

```{r}
# fit random forest 
rf.fit <- randomForest(Veracity~., data= MU3D_Video_Level_Data.scaled)
rf.fit
plot(rf.fit)

mtry <- tuneRF(MU3D_Video_Level_Data.scaled[,-12],MU3D_Video_Level_Data.scaled$Veracity, ntreeTry=1000,
               stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
best.m <- mtry[mtry[,2] == min(mtry[,2]), 1]
print(mtry)
print(best.m) 
```


### Predict and plot AUC 
```{r}

set.seed(123)
rf.fit1 <-randomForest(Veracity~.,data=train_raw.df, mtry=best.m, importance=TRUE,ntree=500)
print(rf.fit1)
#Evaluate variable importance
importance(rf.fit1)
varImpPlot(rf.fit1)



pred1=predict(rf.fit1, test_raw.df, type = "prob")
library(ROCR)
perf = prediction(pred1[,2], test_raw.df$Veracity)
# 1. Area under curve
auc = performance(perf, "auc")
1-auc@y.values[[1]]

# 2. True Positive and Negative Rate
pred3 = performance(perf, "fpr","tpr")
# 3. Plot the ROC curve
plot(pred3,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
legend("topleft", c(paste0("AUC = ", round(1-auc@y.values[[1]],4))))
```

### Summary confusion matrix
```{r}

rf.pred <- predict(rf.fit1, test_raw.df)
confusionMatrix(rf.pred, test_raw.df$Veracity)
```
